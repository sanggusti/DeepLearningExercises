{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week 2 Exercise Answer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX4Kg8DUTKWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ioLbtB3uGKPX",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLSSb7Qly6xf",
        "colab_type": "text"
      },
      "source": [
        "# TRANSFER LEARNING\n",
        "The next code block will download the mobilenet model from TensorFlow Hub, and\n",
        "use its learned features, extracted as feature_extractor and set to be \n",
        "fine tuned by making them trainable.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSW2AcBLuiHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "model_selection = (\"mobilenet_v2\", 224, 1280) \n",
        "\n",
        "handle_base, pixels, FV_SIZE = model_selection\n",
        "\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "\n",
        "MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n",
        "\n",
        "feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n",
        "                                   input_shape=IMAGE_SIZE + (3,))\n",
        "\n",
        "feature_extractor.trainable = True  "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq6kmNMVn1bz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "model_selection = (\"mobilenet_v2\", 224, 1280)\n",
        "\n",
        "handle_base, pixels, FV_SIZE = model_selection\n",
        "\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "\n",
        "MODULE_HANDLE = \"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n",
        "\n",
        "feature_extractor = hub.KerasLayer(MODULE_HANDLE, input_shape = IMAGE_SIZE + (3,))\n",
        "\n",
        "feature_extractor.trainable = True"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ2qZGehzPgM",
        "colab_type": "text"
      },
      "source": [
        "## Import libraries and set up the splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGWOsReCW451",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mi1n2qqKFNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "splits = ['train[:10%]', 'train[90%:95%]', 'train[95%:]']\n",
        "splits, info = tfds.load('cats_vs_dogs', split = splits, with_info=True)\n",
        "(train_examples, validation_examples, test_examples) = splits"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUSLZO8IuEtt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here is where you will write your code\n",
        "# You need to use subsets of the original data, which is entirely in the 'train'\n",
        "# split. I.E. 'train' contains 25000 records.\n",
        "# Split this up so that you get\n",
        "# The first 10% is your 'new' training set\n",
        "# The last 10% is your validation and test sets, split down the middle \n",
        "# (i.e. the first half of the last 10% is validation, the second half is test)\n",
        "# These 3 recordsets should be called\n",
        "# train_examples, validation_examples and test_examples respectively\n",
        "\n",
        "splits = ['train[:10%]', 'train[90%:95%]', 'train[95%:]']\n",
        "splits, info = tfds.load('cats_vs_dogs', split = splits, with_info=True)\n",
        "(train_examples, validation_examples, test_examples) = splits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtSJorjivpS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_examples = 2500\n",
        "num_classes = 2"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc-jKVq_KwZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Turn 3 sets into batches\n",
        "\n",
        "def format_image(features):\n",
        "  image = features['image']\n",
        "  image = tf.image.resize(image, IMAGE_SIZE) / 255.0\n",
        "  return image, features['label']\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_batches = train_examples.shuffle(num_examples).map(format_image).batch(BATCH_SIZE)\n",
        "validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE)\n",
        "test_batches = test_examples.map(format_image).batch(BATCH_SIZE)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkh5t21-uZFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This will turn the 3 sets into batches\n",
        "# so we can train\n",
        "# This code should not be changed\n",
        "\n",
        "def format_image(features):\n",
        "  image = features['image']\n",
        "  image = tf.image.resize(image, IMAGE_SIZE) / 255.0\n",
        "  return  image, features['label']\n",
        "    \n",
        "BATCH_SIZE =  32\n",
        "\n",
        "train_batches = train_examples.shuffle(num_examples).map(format_image).batch(BATCH_SIZE)\n",
        "validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE)\n",
        "test_batches = test_examples.map(format_image).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmyQ207suyGY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "fa2c03ed-a148-41d5-bd63-b735c941cc30"
      },
      "source": [
        "# The new model will take the features from the mobilenet via transfer learning\n",
        "# And add a new dense layer at the bottom, with 2 classes -- for cats and dogs\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "        feature_extractor,\n",
        "        tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer (KerasLayer)     (None, 1280)              2257984   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 2562      \n",
            "=================================================================\n",
            "Total params: 2,260,546\n",
            "Trainable params: 2,226,434\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVFjq8GHu9iN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model with adam optimizer and sparse categorical crossentropy, \n",
        "# and track the accuracy metric\n",
        "    \n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLIwqtilvBcN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "ad16009c-09b0-4647-d755-800e77d9a2fc"
      },
      "source": [
        "# Train it for a number of epochs. You should not need many\n",
        "# Train on the train_Batches, and validation on the validation_batches\n",
        "EPOCHS = 10\n",
        "\n",
        "history = model.fit(train_batches, epochs=EPOCHS, validation_data=validation_batches)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "      2/Unknown - 0s 100ms/step - loss: 0.7557 - acc: 0.5469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0613s vs `on_train_batch_end` time: 0.1379s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0613s vs `on_train_batch_end` time: 0.1379s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "73/73 [==============================] - 18s 241ms/step - loss: 0.3224 - acc: 0.9046 - val_loss: 4.0318 - val_acc: 0.7876\n",
            "Epoch 2/10\n",
            "73/73 [==============================] - 17s 229ms/step - loss: 0.1989 - acc: 0.9549 - val_loss: 0.5547 - val_acc: 0.9037\n",
            "Epoch 3/10\n",
            "73/73 [==============================] - 18s 244ms/step - loss: 0.1930 - acc: 0.9604 - val_loss: 1.3511 - val_acc: 0.8426\n",
            "Epoch 4/10\n",
            "73/73 [==============================] - 17s 231ms/step - loss: 0.1719 - acc: 0.9678 - val_loss: 0.5211 - val_acc: 0.9269\n",
            "Epoch 5/10\n",
            "73/73 [==============================] - 17s 237ms/step - loss: 0.1552 - acc: 0.9725 - val_loss: 0.3140 - val_acc: 0.9209\n",
            "Epoch 6/10\n",
            "73/73 [==============================] - 17s 232ms/step - loss: 0.1281 - acc: 0.9819 - val_loss: 0.2413 - val_acc: 0.9579\n",
            "Epoch 7/10\n",
            "73/73 [==============================] - 17s 234ms/step - loss: 0.1164 - acc: 0.9884 - val_loss: 0.2549 - val_acc: 0.9630\n",
            "Epoch 8/10\n",
            "73/73 [==============================] - 17s 233ms/step - loss: 0.1506 - acc: 0.9802 - val_loss: 0.2960 - val_acc: 0.9372\n",
            "Epoch 9/10\n",
            "73/73 [==============================] - 17s 234ms/step - loss: 0.1308 - acc: 0.9850 - val_loss: 1.2665 - val_acc: 0.7902\n",
            "Epoch 10/10\n",
            "73/73 [==============================] - 17s 234ms/step - loss: 0.1209 - acc: 0.9905 - val_loss: 0.2365 - val_acc: 0.9544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jkG0zBHvEnP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "158ee672-3aa7-4575-a7cf-32e4c34399e1"
      },
      "source": [
        "# Evaluate the model on the test batches\n",
        "eval_results = model.evaluate(test_batches)\n",
        "\n",
        "# And print the results. You should have >93% accuracy\n",
        "for metric, value in zip(model.metrics_names, eval_results):\n",
        "    print(metric + ': {:.4}'.format(value))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37/37 [==============================] - 2s 46ms/step - loss: 0.2637 - acc: 0.9536\n",
            "loss: 0.2637\n",
            "acc: 0.9536\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}